{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sq1pu1tA1aWs"
      },
      "outputs": [],
      "source": [
        "# Import Data Science Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Tensorflow Libraries\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers,models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import Callback, EarlyStopping,ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "# System libraries\n",
        "from pathlib import Path\n",
        "import os.path\n",
        "import random\n",
        "import os\n",
        "\n",
        "# Visualization Libraries\n",
        "import matplotlib.cm as cm\n",
        "import cv2\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set_style('darkgrid')\n",
        "\n",
        "# Metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import itertools\n",
        "\n",
        "# drive\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Input dataset"
      ],
      "metadata": {
        "id": "qkjSlIqL1fBZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mount drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "NGHtxbdk2OtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def walk_through_dir(directory):\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            print(os.path.join(root, file))\n",
        "\n",
        "# Now you can call the function\n",
        "dataset = r'/content/gdrive/MyDrive/Capstone Project/Machine learning/Dataset 2'\n",
        "walk_through_dir(dataset)"
      ],
      "metadata": {
        "id": "ZhLakosN1ckb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_dir = Path(dataset)\n",
        "\n",
        "# Get filepaths and labels\n",
        "filepaths = list(image_dir.glob(r'**/*.JPG')) + list(image_dir.glob(r'**/*.jpg')) + list(image_dir.glob(r'**/*.png')) + list(image_dir.glob(r'**/*.png'))\n",
        "\n",
        "labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))\n",
        "\n",
        "filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
        "labels = pd.Series(labels, name='Label')\n",
        "\n",
        "# Concatenate filepaths and labels\n",
        "image_df = pd.concat([filepaths, labels], axis=1)"
      ],
      "metadata": {
        "id": "ieYSt03Z1zFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_counts = image_df['Label'].value_counts()\n",
        "\n",
        "plt.figure(figsize=(20, 6))\n",
        "sns.barplot(x=label_counts.index, y=label_counts.values, alpha=0.8, palette='dark:salmon_r')\n",
        "plt.title('Distribution of Top 6 Labels in Image Dataset', fontsize=16)\n",
        "plt.xlabel('Label', fontsize=14)\n",
        "plt.ylabel('Count', fontsize=14)\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tAUZ55qC14Pg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display 16 picture of the dataset with their labels\n",
        "random_index = np.random.randint(0, len(image_df), 16)\n",
        "fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(10, 10),\n",
        "                        subplot_kw={'xticks': [], 'yticks': []})\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(plt.imread(image_df.Filepath[random_index[i]]))\n",
        "    ax.set_title(image_df.Label[random_index[i]])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9YJK4Twb16lk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display 16 picture of the dataset with their labels\n",
        "random_index = np.random.randint(0, len(image_df), 16)\n",
        "fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(10, 10),\n",
        "                        subplot_kw={'xticks': [], 'yticks': []})\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(plt.imread(image_df.Filepath[random_index[i]]))\n",
        "    ax.set_title(image_df.Label[random_index[i]])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sxccu2UD49kW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Processing"
      ],
      "metadata": {
        "id": "9rc4UioJ1Xsl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "TARGET_SIZE = (224, 224)"
      ],
      "metadata": {
        "id": "VFx-Tmv-4-r3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate in train and test data\n",
        "train_df, test_df = train_test_split(image_df, test_size=0.2, shuffle=True, random_state=42)"
      ],
      "metadata": {
        "id": "JGNMGex05BTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = ImageDataGenerator(\n",
        "    preprocessing_function=tf.keras.applications.efficientnet.preprocess_input,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "test_generator = ImageDataGenerator(\n",
        "    preprocessing_function=tf.keras.applications.efficientnet.preprocess_input,\n",
        ")"
      ],
      "metadata": {
        "id": "m3PRYpD-68zY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into three categories.\n",
        "train_images = train_generator.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    x_col='Filepath',\n",
        "    y_col='Label',\n",
        "    target_size=TARGET_SIZE,\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    seed=42,\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_images = train_generator.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    x_col='Filepath',\n",
        "    y_col='Label',\n",
        "    target_size=TARGET_SIZE,\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    seed=42,\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "test_images = test_generator.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    x_col='Filepath',\n",
        "    y_col='Label',\n",
        "    target_size=TARGET_SIZE,\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "lW-Su90k5Me8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Augmentation Step\n",
        "augment = tf.keras.Sequential([\n",
        "  layers.experimental.preprocessing.Resizing(224,224),\n",
        "  layers.experimental.preprocessing.Rescaling(1./255),\n",
        "  layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
        "  layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "  layers.experimental.preprocessing.RandomZoom(0.1),\n",
        "  layers.experimental.preprocessing.RandomContrast(0.1),\n",
        "])"
      ],
      "metadata": {
        "id": "b4iTvzaV5NQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the model"
      ],
      "metadata": {
        "id": "-IcesXAw1dY8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pretained model\n",
        "pretrained_model = tf.keras.applications.efficientnet.EfficientNetB0(\n",
        "    input_shape=(224, 224, 3),\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    pooling='max'\n",
        ")\n",
        "\n",
        "pretrained_model.trainable = False"
      ],
      "metadata": {
        "id": "x4QUJIEi5O6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create checkpoint callback\n",
        "checkpoint_path = \"birds_classification_model_checkpoint\"\n",
        "checkpoint_callback = ModelCheckpoint(checkpoint_path,\n",
        "                                      save_weights_only=True,\n",
        "                                      monitor=\"val_accuracy\",\n",
        "                                      save_best_only=True)\n",
        "\n",
        "# Setup EarlyStopping callback to stop training if model's val_loss doesn't improve for 3 epochs\n",
        "early_stopping = EarlyStopping(monitor = \"val_loss\", # watch the val loss metric\n",
        "                               patience = 5,\n",
        "                               restore_best_weights = True) # if val loss decreases for 3 epochs in a row, stop training\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)"
      ],
      "metadata": {
        "id": "w5HNp4n45PFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = pretrained_model.input\n",
        "x = augment(inputs)\n",
        "\n",
        "x = Dense(128, activation='relu')(pretrained_model.output)\n",
        "x = Dropout(0.45)(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.45)(x)\n",
        "\n",
        "\n",
        "outputs = Dense(4, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(0.0001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_images,\n",
        "    steps_per_epoch=len(train_images),\n",
        "    validation_data=val_images,\n",
        "    validation_steps=len(val_images),\n",
        "    epochs=250,\n",
        ")"
      ],
      "metadata": {
        "id": "C3mL09bw5PU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# model evaluation"
      ],
      "metadata": {
        "id": "peDEJ7IS1gxJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.evaluate(test_images, verbose=0)\n",
        "\n",
        "print(\"    Test Loss: {:.5f}\".format(results[0]))\n",
        "print(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))"
      ],
      "metadata": {
        "id": "LgT9RjJe5WSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(accuracy))\n",
        "plt.plot(epochs, accuracy, 'b', label='Training accuracy')\n",
        "plt.plot(epochs, val_accuracy, 'r', label='Validation accuracy')\n",
        "\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3iJJBkwh5Wb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# prediction"
      ],
      "metadata": {
        "id": "u9tl9-my1mjm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the label of the test_images\n",
        "pred = model.predict(test_images)\n",
        "pred = np.argmax(pred,axis=1)\n",
        "\n",
        "# Map the label\n",
        "labels = (train_images.class_indices)\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "pred = [labels[k] for k in pred]\n",
        "\n",
        "# Display the result\n",
        "print(f'The first 5 predictions: {pred[:5]}')"
      ],
      "metadata": {
        "id": "uAor1BVY5WhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  # Display 25 random pictures from the dataset with their labels\n",
        "random_index = np.random.randint(0, len(test_df) - 1, 15)\n",
        "fig, axes = plt.subplots(nrows=3, ncols=5, figsize=(25, 15),\n",
        "                        subplot_kw={'xticks': [], 'yticks': []})\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(plt.imread(test_df.Filepath.iloc[random_index[i]]))\n",
        "    if test_df.Label.iloc[random_index[i]] == pred[random_index[i]]:\n",
        "        color = \"green\"\n",
        "    else:\n",
        "        color = \"red\"\n",
        "    ax.set_title(f\"True: {test_df.Label.iloc[random_index[i]]}\\nPredicted: {pred[random_index[i]]}\", color=color)\n",
        "plt.show()\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "dMnQKRA65Yjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# plotting the classification"
      ],
      "metadata": {
        "id": "CZThqNop1pMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = list(test_df.Label)\n",
        "print(classification_report(y_test, pred))"
      ],
      "metadata": {
        "id": "Z7wCH8Sp5Yl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lA9aw0PN5YoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A0HlJnR_5Yqj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}